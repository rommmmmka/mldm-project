{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:49.941804Z",
     "start_time": "2024-12-01T12:53:48.029008Z"
    }
   },
   "source": [
    "import mne\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:50.372596Z",
     "start_time": "2024-12-01T12:53:50.341739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelShuffle(torch.nn.Module):\n",
    "    def __init__(self, groups):\n",
    "        super(ChannelShuffle, self).__init__()\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, length = x.size()\n",
    "        x = x.view(batch_size, self.groups, channels // self.groups, length)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, channels, length)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock1, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=8, groups=8)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle1 = ChannelShuffle(8)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=7, groups=8)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle2 = ChannelShuffle(8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock2, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 128, kernel_size=16, padding=8, stride=2, groups=16)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle1 = ChannelShuffle(16)\n",
    "        self.conv2 = torch.nn.Conv1d(128, 128, kernel_size=16, padding=7, groups=16)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle2 = ChannelShuffle(16)\n",
    "\n",
    "        self.match_dimensions = torch.nn.Conv1d(64, 128, kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        x = self.match_dimensions(x)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class LightSleepNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightSleepNet, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(1, 64, kernel_size=16, padding=7, stride=2)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(64)\n",
    "        self.residual1 = ResidualBlock1()\n",
    "        self.residual2 = ResidualBlock2()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.linear = torch.nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.residual1(x)\n",
    "        x = self.residual2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ],
   "id": "2f9ea501934a66e4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:44:12.853771Z",
     "start_time": "2024-12-01T16:44:12.837762Z"
    }
   },
   "cell_type": "code",
   "source": "SUBJECT = 1",
   "id": "9e16fe21aea1f7e7",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:45:20.047534Z",
     "start_time": "2024-12-01T16:45:19.810958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw = mne.io.read_raw_fif(f\"processed/{SUBJECT}/{SUBJECT}_annotator_1_eeg.fif\")\n",
    "channel_names = raw.ch_names\n",
    "channel_names"
   ],
   "id": "77c70f7f66b61910",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file processed/1/1_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5723999 =      0.000 ... 28619.995 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['F3', 'C3', 'O1', 'F4', 'C4', 'O2']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:45:21.225318Z",
     "start_time": "2024-12-01T16:45:20.281627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw.pick(channel_names[0])\n",
    "epochs = mne.make_fixed_length_epochs(raw, duration=30, preload=True)\n",
    "annotations = raw.annotations"
   ],
   "id": "5250594f0aeace54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "954 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 954 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:45:21.288153Z",
     "start_time": "2024-12-01T16:45:21.225318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_tensor = torch.tensor(epochs.get_data(), dtype=torch.float32).to(\"cuda\")\n",
    "data_tensor"
   ],
   "id": "dfdc9ea9264e3882",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.7221e-09, -1.2322e-07, -9.0448e-07,  ...,  1.1952e-06,\n",
       "           8.0148e-07,  2.9259e-07]],\n",
       "\n",
       "        [[ 1.4076e-07,  5.7259e-07,  1.2287e-06,  ..., -4.3679e-07,\n",
       "          -1.5679e-07, -4.7951e-07]],\n",
       "\n",
       "        [[-8.5183e-07, -7.4884e-07, -2.8801e-07,  ...,  5.5505e-07,\n",
       "           4.8791e-07,  1.1929e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4363e-06,  1.9024e-06,  2.1679e-06,  ...,  3.6915e-06,\n",
       "           2.6608e-06,  6.2829e-07]],\n",
       "\n",
       "        [[-2.1630e-07,  1.6255e-06,  4.6689e-06,  ...,  9.3061e-06,\n",
       "           9.2466e-06,  9.2840e-06]],\n",
       "\n",
       "        [[ 9.4373e-06,  9.4930e-06,  9.2550e-06,  ..., -9.7391e-07,\n",
       "          -1.1395e-06, -1.1578e-06]]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:45:21.502480Z",
     "start_time": "2024-12-01T16:45:21.461597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "annotations_int = annotations.description.astype(int)\n",
    "annotations_int[annotations_int == 5] = 4\n",
    "labels_tensor = torch.tensor(annotations_int).to(\"cuda\")\n",
    "labels_tensor"
   ],
   "id": "4918d99b77fffed4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 0,\n",
       "        1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 0, 1, 2, 2,\n",
       "        2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 1, 1, 1,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1,\n",
       "        1, 1, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 2, 2, 1, 1, 4, 4, 4, 1,\n",
       "        1, 0, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 0, 1, 0, 0, 1, 0, 0, 1, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 4, 4, 4, 4, 1, 1, 1, 1, 1, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        1, 1, 4, 4, 4, 4, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 4, 1, 4, 4, 1, 4, 4, 4, 4, 4, 0, 1,\n",
       "        1, 1, 1, 2, 2, 2, 4, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 4, 4, 4, 4, 4, 1, 1,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:45:22.180970Z",
     "start_time": "2024-12-01T16:45:22.165297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(data_tensor, labels_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "583a5139a302a49f",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:53:02.071419Z",
     "start_time": "2024-12-01T16:53:02.055612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = LightSleepNet().to(\"cuda\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "id": "6896f24437164264",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:56:36.812484Z",
     "start_time": "2024-12-01T16:56:32.790996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for training_epoch in range(100):\n",
    "    print(training_epoch + 1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        outputs = model(X_batch).float()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        print(predicted)\n",
    "        correct += predicted.eq(y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    print(correct / total * 100)"
   ],
   "id": "84e73380be152064",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([2, 2, 0, 1, 4, 1, 1, 3, 3, 2, 2, 0, 0, 2, 4, 3, 4, 2, 2, 1, 3, 0, 4, 2,\n",
      "        3, 0, 4, 3, 4, 0, 2, 4], device='cuda:0')\n",
      "tensor([2, 1, 0, 2, 0, 0, 2, 4, 2, 3, 4, 2, 2, 3, 3, 3, 3, 2, 1, 0, 2, 4, 2, 2,\n",
      "        1, 0, 3, 4, 2, 2, 4, 2], device='cuda:0')\n",
      "tensor([2, 0, 3, 1, 2, 2, 0, 3, 3, 2, 3, 2, 2, 0, 4, 3, 4, 0, 2, 2, 2, 4, 2, 4,\n",
      "        2, 1, 2, 2, 3, 2, 0, 3], device='cuda:0')\n",
      "tensor([2, 3, 2, 2, 0, 3, 3, 4, 3, 1, 2, 1, 2, 0, 0, 2, 0, 3, 2, 4, 0, 0, 2, 3,\n",
      "        2, 2, 4, 0, 1, 4, 3, 0], device='cuda:0')\n",
      "tensor([0, 2, 0, 2, 2, 3, 0, 4, 1, 2, 2, 4, 2, 3, 4, 0, 2, 4, 1, 2, 3, 2, 3, 1,\n",
      "        1, 0, 3, 1, 2, 2, 2, 1], device='cuda:0')\n",
      "tensor([2, 3, 1, 2, 1, 3, 0, 0, 0, 3, 2, 0, 2, 2, 4, 0, 4, 1, 0, 3, 4, 1, 2, 0,\n",
      "        3, 2, 4, 4, 0, 1, 2, 3], device='cuda:0')\n",
      "tensor([2, 0, 4, 3, 2, 0, 2, 2, 4, 1, 3, 3, 1, 2, 2, 0, 2, 0, 3, 3, 2, 2, 2, 1,\n",
      "        0, 0, 0, 3, 2, 2, 4, 2], device='cuda:0')\n",
      "tensor([4, 3, 2, 2, 1, 2, 2, 2, 3, 0, 0, 0, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 3, 3,\n",
      "        4, 0, 3, 0, 0, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 3, 2, 3, 2, 0, 2, 3, 1, 3, 0, 2, 2, 4, 1, 1, 0, 1, 2, 2, 1, 3, 2, 3,\n",
      "        2, 1, 3, 2, 1, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 1, 2, 2, 0, 2, 2, 3, 2, 0, 4, 2, 2, 3, 2, 2, 3, 2, 3, 2, 0, 3, 4, 3,\n",
      "        0, 2, 0, 1, 4, 3, 2, 2], device='cuda:0')\n",
      "tensor([4, 2, 2, 2, 0, 2, 2, 4, 0, 3, 4, 0, 1, 2, 0, 3, 1, 2, 0, 2, 3, 2, 3, 2,\n",
      "        2, 1, 2, 4, 1, 2, 3, 3], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 0, 3, 2, 3, 1, 3, 3, 2, 3, 4, 4, 2, 3, 0, 2, 2, 0, 4, 2, 2,\n",
      "        2, 4, 2, 4, 0, 2, 2, 0], device='cuda:0')\n",
      "tensor([1, 2, 4, 0, 2, 0, 2, 0, 4, 3, 2, 2, 2, 4, 2, 0, 3, 2, 0, 2, 1, 3, 2, 2,\n",
      "        2, 3, 3, 2, 3, 1, 3, 2], device='cuda:0')\n",
      "tensor([2, 3, 2, 1, 1, 2, 4, 0, 2, 0, 2, 4, 2, 2, 3, 2, 4, 2, 3, 2, 1, 2, 2, 3,\n",
      "        0, 2, 0, 0, 2, 3, 3, 3], device='cuda:0')\n",
      "tensor([2, 3, 2, 2, 1, 2, 4, 2, 3, 2, 2, 2, 2, 0, 2, 0, 2, 0, 4, 3, 4, 2, 1, 3,\n",
      "        2, 0, 0, 3, 1, 3, 2, 2], device='cuda:0')\n",
      "tensor([1, 4, 0, 3, 3, 1, 0, 2, 2, 3, 3, 2, 2, 4, 1, 2, 3, 2, 2, 4, 0, 2, 0, 2,\n",
      "        2, 2, 1, 4, 2, 3, 4, 2], device='cuda:0')\n",
      "tensor([3, 3, 4, 3, 2, 2, 2, 2, 1, 0, 2, 4, 4, 2, 2, 3, 4, 1, 0, 3, 2, 3, 0, 2,\n",
      "        2, 4, 2, 0, 3, 2, 1, 0], device='cuda:0')\n",
      "tensor([2, 2, 4, 0, 3, 2, 2, 1, 2, 1, 2, 4, 1, 2, 2, 3, 2, 0, 2, 4, 3, 4, 2, 3,\n",
      "        4, 2, 3, 3, 0, 1, 4, 2], device='cuda:0')\n",
      "tensor([2, 3, 0, 2, 3, 2, 1, 3, 2, 2, 4, 2, 1, 0, 3, 0, 4, 4, 2, 3, 1, 0, 3, 0,\n",
      "        3, 3, 0, 0, 2, 3, 3, 2], device='cuda:0')\n",
      "tensor([2, 2, 4, 2, 2, 0, 3, 1, 2, 2, 2, 4, 1, 2, 4, 0, 2, 1, 2, 4, 0, 2, 0, 2,\n",
      "        4, 3, 2, 2, 3, 3, 0, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 4, 3, 1, 2, 1, 1, 3, 2, 2, 1, 2, 3, 2, 0, 4, 1, 2, 3,\n",
      "        2, 2, 0, 4, 2, 3, 2, 3], device='cuda:0')\n",
      "tensor([4, 0, 3, 4, 3, 0, 2, 2, 3, 2, 2, 2, 2, 2, 0, 2, 4, 3, 2, 2, 4, 2, 2, 0,\n",
      "        1, 2, 0, 4, 2, 0, 3, 2], device='cuda:0')\n",
      "tensor([4, 4, 1, 3, 4, 1, 3, 3, 0, 0, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 0, 1, 3, 3,\n",
      "        2, 2, 3, 2, 2, 2, 1, 2], device='cuda:0')\n",
      "tensor([0, 0, 0, 4, 3, 0, 4, 3, 3, 4, 4, 2, 0, 2, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 3, 2, 1, 0, 1, 2, 4], device='cuda:0')\n",
      "tensor([1, 4, 3, 2, 2, 0, 3, 3, 2, 3, 0, 1, 2, 3, 2, 1, 2, 3, 3, 2, 2, 2, 4, 3,\n",
      "        4, 0, 2, 0, 3, 2, 0, 3], device='cuda:0')\n",
      "tensor([3, 2, 2, 2, 4, 0, 0, 4, 0, 0, 0, 4, 3, 2, 1, 0, 2, 3, 2, 1, 3, 4, 0, 2,\n",
      "        2, 2, 2, 0, 2, 2, 4, 2], device='cuda:0')\n",
      "tensor([2, 2, 4, 2, 3, 0, 2, 2, 2, 1, 3, 0, 2, 3, 0, 2, 0, 2, 0, 2, 2, 0, 3, 4,\n",
      "        2, 0, 3, 1, 0, 3, 2, 2], device='cuda:0')\n",
      "tensor([2, 3, 2, 3, 2, 0, 0, 0, 0, 3, 1, 2, 2, 4, 4, 3, 0, 2, 4, 2, 0, 0, 3, 2,\n",
      "        2, 4, 4, 4, 4, 4, 2, 2], device='cuda:0')\n",
      "tensor([2, 1, 2, 2, 2, 0, 4, 2, 2, 3, 2, 2, 0, 3, 1, 2, 4, 0, 0, 2, 4, 0, 4, 1,\n",
      "        1, 1, 0, 1, 3, 3, 2, 2], device='cuda:0')\n",
      "tensor([2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 0, 0, 1, 2, 2, 4, 3, 2, 2, 0, 3, 2, 4, 4,\n",
      "        4, 0], device='cuda:0')\n",
      "87.9454926624738\n",
      "2\n",
      "tensor([2, 2, 2, 3, 3, 2, 0, 2, 2, 1, 4, 0, 3, 2, 0, 3, 2, 0, 2, 4, 4, 0, 3, 3,\n",
      "        1, 1, 0, 1, 1, 2, 3, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 4, 1, 2, 2, 4, 1, 3, 0, 2, 1, 3, 2, 0, 2, 3, 2, 4, 2, 2, 2, 4,\n",
      "        0, 2, 3, 2, 2, 2, 0, 1], device='cuda:0')\n",
      "tensor([3, 0, 2, 3, 2, 3, 0, 2, 2, 3, 2, 2, 4, 1, 1, 2, 1, 0, 1, 0, 1, 0, 2, 1,\n",
      "        3, 2, 3, 2, 4, 3, 2, 3], device='cuda:0')\n",
      "tensor([1, 4, 0, 2, 2, 2, 2, 2, 2, 3, 0, 3, 1, 2, 1, 1, 1, 1, 2, 3, 3, 2, 1, 2,\n",
      "        3, 1, 2, 3, 2, 0, 2, 4], device='cuda:0')\n",
      "tensor([4, 2, 2, 2, 1, 2, 3, 1, 1, 1, 0, 4, 2, 2, 2, 3, 1, 2, 4, 1, 3, 3, 2, 2,\n",
      "        0, 0, 2, 4, 3, 1, 2, 3], device='cuda:0')\n",
      "tensor([2, 2, 2, 3, 3, 2, 3, 2, 2, 3, 0, 1, 2, 2, 1, 0, 4, 2, 2, 2, 2, 4, 0, 1,\n",
      "        2, 2, 1, 1, 4, 2, 3, 3], device='cuda:0')\n",
      "tensor([2, 2, 3, 0, 0, 1, 1, 2, 3, 3, 4, 3, 2, 3, 0, 3, 4, 2, 2, 2, 0, 0, 4, 2,\n",
      "        0, 2, 1, 2, 2, 3, 2, 1], device='cuda:0')\n",
      "tensor([3, 1, 0, 2, 3, 2, 2, 2, 0, 2, 0, 3, 3, 4, 2, 2, 2, 2, 0, 4, 3, 1, 3, 4,\n",
      "        2, 3, 4, 2, 2, 2, 2, 1], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_batch)\n\u001B[0;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 14\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     17\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mldm-project\\.venv\\lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mldm-project\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mldm-project\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:57:39.584478Z",
     "start_time": "2024-12-01T16:57:39.232223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw = mne.io.read_raw_fif(f\"processed/2/2_annotator_1_eeg.fif\")\n",
    "channel_names = raw.ch_names\n",
    "raw.pick(channel_names[0])\n",
    "data_tensor = torch.tensor(epochs.get_data(), dtype=torch.float32).to(\"cuda\")\n",
    "\n",
    "annotations_int = annotations.description.astype(int)\n",
    "annotations_int[annotations_int == 5] = 4\n",
    "labels_tensor = torch.tensor(annotations_int).to(\"cuda\")"
   ],
   "id": "6cc15eccfaca0041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file processed/2/2_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5645999 =      0.000 ... 28229.995 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:57:39.598739Z",
     "start_time": "2024-12-01T16:57:39.587771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = torch.utils.data.TensorDataset(data_tensor, labels_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "dac2a52ff186ee03",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:57:42.262027Z",
     "start_time": "2024-12-01T16:57:41.390082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        print(predicted)\n",
    "        correct += predicted.eq(y_batch).sum().item()\n",
    "        total += y_batch.size(0)"
   ],
   "id": "83c23547f75848c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1,\n",
      "        1, 1, 1, 2, 2, 1, 2, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 4, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 3, 3, 3, 3, 3, 0], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 2, 2], device='cuda:0')\n",
      "tensor([1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
      "        2, 2, 2, 2, 3, 3, 2, 3], device='cuda:0')\n",
      "tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 1, 2, 1, 1, 4, 0, 0], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 1, 0, 1, 2, 2, 2, 2, 4, 2, 2, 1,\n",
      "        2, 0, 0, 1, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 3, 2, 3], device='cuda:0')\n",
      "tensor([1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 3, 2, 3, 2, 3, 3, 2], device='cuda:0')\n",
      "tensor([3, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([3, 3, 3, 3, 3, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 2, 2, 2,\n",
      "        2, 2, 2, 2, 1, 0, 0, 1], device='cuda:0')\n",
      "tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 1, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 4, 2, 3, 3, 3,\n",
      "        3, 2, 2, 0, 0, 2, 2, 2], device='cuda:0')\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 1, 1, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 0, 0, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 2, 3, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 0, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "tensor([3, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2,\n",
      "        1, 2, 3, 3, 2, 2, 0, 0], device='cuda:0')\n",
      "tensor([2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2,\n",
      "        2, 0, 4, 1, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        0, 2, 2, 2, 3, 2, 3, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
      "        2, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 0,\n",
      "        4, 2, 1, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "tensor([2, 3, 2, 3, 4, 2, 0, 2, 1, 1, 2, 2, 2, 2, 3, 2, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 4, 2, 1, 1, 2, 2, 0, 0, 1, 1, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 0, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 1, 0, 2, 1], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 0,\n",
      "        0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:57:44.169736Z",
     "start_time": "2024-12-01T16:57:44.153906Z"
    }
   },
   "cell_type": "code",
   "source": "test_loss / len(test_loader)",
   "id": "775bc690e56e7f3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.508563132584095"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:57:45.690862Z",
     "start_time": "2024-12-01T16:57:45.674909Z"
    }
   },
   "cell_type": "code",
   "source": "100 * correct / total",
   "id": "127faa4f4af2dffd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.9664570230608"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:57:47.731974Z",
     "start_time": "2024-12-01T16:57:47.715990Z"
    }
   },
   "cell_type": "code",
   "source": "correct",
   "id": "2cce91786dcfd4c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:57:48.725285Z",
     "start_time": "2024-12-01T16:57:48.709600Z"
    }
   },
   "cell_type": "code",
   "source": "total",
   "id": "cce6aab6e316bd07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:44:38.548128Z",
     "start_time": "2024-12-01T16:44:38.532898Z"
    }
   },
   "cell_type": "code",
   "source": "predicted",
   "id": "61438c5b08d61fcd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f23e2877eedb02f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
