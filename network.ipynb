{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T12:37:40.489539Z",
     "start_time": "2024-12-02T12:37:36.445348Z"
    }
   },
   "source": [
    "import mne\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:37:41.930750Z",
     "start_time": "2024-12-02T12:37:41.903439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelShuffle(torch.nn.Module):\n",
    "    def __init__(self, groups):\n",
    "        super(ChannelShuffle, self).__init__()\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, length = x.size()\n",
    "        x = x.view(batch_size, self.groups, channels // self.groups, length)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, channels, length)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock1, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=8, groups=8)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle1 = ChannelShuffle(8)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=7, groups=8)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle2 = ChannelShuffle(8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock2, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 128, kernel_size=16, padding=8, stride=2, groups=16)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle1 = ChannelShuffle(16)\n",
    "        self.conv2 = torch.nn.Conv1d(128, 128, kernel_size=16, padding=7, groups=16)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle2 = ChannelShuffle(16)\n",
    "\n",
    "        self.match_dimensions = torch.nn.Conv1d(64, 128, kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        x = self.match_dimensions(x)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class LightSleepNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightSleepNet, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(1, 64, kernel_size=16, padding=7, stride=2)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(64)\n",
    "        self.residual1 = ResidualBlock1()\n",
    "        self.residual2 = ResidualBlock2()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.linear = torch.nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.residual1(x)\n",
    "        x = self.residual2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ],
   "id": "2f9ea501934a66e4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:37:43.278425Z",
     "start_time": "2024-12-02T12:37:43.262638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHANNEL_NAME = \"F3\"\n",
    "ANNOTATOR = \"annotator_1\"\n",
    "SLEEP_STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]"
   ],
   "id": "9e16fe21aea1f7e7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:38:02.523345Z",
     "start_time": "2024-12-02T12:37:44.013568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subjects_data = []\n",
    "subjects_labels = []\n",
    "\n",
    "for subject in range(1, 11):\n",
    "    print(f\"==={subject}===\")\n",
    "    raw = mne.io.read_raw_fif(f\"processed/{subject}/{subject}_{ANNOTATOR}_eeg.fif\")\n",
    "    raw.pick(CHANNEL_NAME)\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=30, preload=True)\n",
    "    annotations = raw.annotations\n",
    "\n",
    "    data_tensor = torch.tensor(epochs.get_data(), dtype=torch.float32).to(\"cuda\")\n",
    "\n",
    "    annotations_int = annotations.description.astype(int)\n",
    "    annotations_int[annotations_int == 5] = 4\n",
    "    labels_tensor = torch.tensor(annotations_int).to(\"cuda\")\n",
    "\n",
    "    subjects_data.append(data_tensor)\n",
    "    subjects_labels.append(labels_tensor)"
   ],
   "id": "40cf8da905c03fb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===1===\n",
      "Opening raw data file processed/1/1_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5723999 =      0.000 ... 28619.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "954 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 954 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===2===\n",
      "Opening raw data file processed/2/2_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5645999 =      0.000 ... 28229.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "941 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 941 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===3===\n",
      "Opening raw data file processed/3/3_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4943999 =      0.000 ... 24719.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "824 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 824 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===4===\n",
      "Opening raw data file processed/4/4_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4763999 =      0.000 ... 23819.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "794 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 794 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===5===\n",
      "Opening raw data file processed/5/5_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5663999 =      0.000 ... 28319.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "944 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 944 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===6===\n",
      "Opening raw data file processed/6/6_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5117999 =      0.000 ... 25589.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "853 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 853 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===7===\n",
      "Opening raw data file processed/7/7_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4883999 =      0.000 ... 24419.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "814 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 814 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===8===\n",
      "Opening raw data file processed/8/8_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5999999 =      0.000 ... 29999.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "1000 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1000 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===9===\n",
      "Opening raw data file processed/9/9_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5813999 =      0.000 ... 29069.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "969 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 969 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===10===\n",
      "Opening raw data file processed/10/10_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4775999 =      0.000 ... 23879.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "796 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 796 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:38:03.431496Z",
     "start_time": "2024-12-02T12:38:03.415817Z"
    }
   },
   "cell_type": "code",
   "source": "SUBJECT_TEST = 1",
   "id": "190787bae97ff60",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T15:21:11.732435Z",
     "start_time": "2024-12-02T12:38:03.885353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for subject_test in range(1, 11):\n",
    "for subject_test in [SUBJECT_TEST]:\n",
    "    print(f\"===TEST SUBJECT: {subject_test}===\")\n",
    "\n",
    "    subjects_data_train = subjects_data[:subject_test - 1] + subjects_data[subject_test:]\n",
    "    subjects_label_train = subjects_labels[:subject_test - 1] + subjects_labels[subject_test:]\n",
    "    subjects_data_train_tensor = torch.cat(subjects_data_train)\n",
    "    subjects_label_train_tensor = torch.cat(subjects_label_train)\n",
    "    train_dataset = torch.utils.data.TensorDataset(subjects_data_train_tensor, subjects_label_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    subject_data_test_tensor = subjects_data[subject_test - 1]\n",
    "    subject_label_test_tensor = subjects_labels[subject_test - 1]\n",
    "    test_dataset = torch.utils.data.TensorDataset(subject_data_test_tensor, subject_label_test_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = LightSleepNet().to(\"cuda\")\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for training_epoch in range(100):\n",
    "        print(f\"{training_epoch + 1:<5}\", end=\"\")\n",
    "\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch.requires_grad = True\n",
    "\n",
    "            outputs = model(X_batch).float()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            weights = []\n",
    "\n",
    "            for epoch_idx in range(X_batch.size(0)):\n",
    "                epoch_data = X_batch[epoch_idx].unsqueeze(0)\n",
    "                epoch_loss = criterion(model(epoch_data), y_batch[epoch_idx].unsqueeze(0))\n",
    "\n",
    "                epoch_grads = torch.autograd.grad(epoch_loss, epoch_data, retain_graph=True)[0]\n",
    "                grad_norms = epoch_grads.norm(p=2, dim=1).squeeze(0)\n",
    "\n",
    "                delta = 0.1 * grad_norms.std().item()\n",
    "                density = ((grad_norms.unsqueeze(1) - grad_norms.unsqueeze(0)).abs() < delta).sum(dim=1).float()\n",
    "\n",
    "                epoch_weight = density.mean()\n",
    "                weights.append(epoch_weight)\n",
    "\n",
    "            weights = torch.tensor(weights, device=\"cuda\")\n",
    "            weights /= weights.sum()\n",
    "            # print(weights)\n",
    "            weighted_loss = (weights * loss).sum()\n",
    "            train_loss += weighted_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            weighted_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        print(f\"Loss: {train_loss:.3f}  Accuracy: {100 * correct / total:.3f}\")"
   ],
   "id": "86fdd41dce85cd3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===TEST SUBJECT: 1===\n",
      "1    Loss: 201.805  Accuracy: 67.083\n",
      "2    Loss: 152.078  Accuracy: 75.186\n",
      "3    Loss: 147.166  Accuracy: 75.539\n",
      "4    Loss: 140.391  Accuracy: 77.240\n",
      "5    Loss: 136.279  Accuracy: 77.631\n",
      "6    Loss: 133.074  Accuracy: 78.286\n",
      "7    Loss: 131.896  Accuracy: 78.664\n",
      "8    Loss: 127.939  Accuracy: 79.004\n",
      "9    Loss: 126.434  Accuracy: 79.597\n",
      "10   Loss: 125.915  Accuracy: 79.332\n",
      "11   Loss: 121.764  Accuracy: 80.088\n",
      "12   Loss: 119.662  Accuracy: 80.504\n",
      "13   Loss: 117.922  Accuracy: 80.681\n",
      "14   Loss: 122.334  Accuracy: 80.038\n",
      "15   Loss: 117.438  Accuracy: 80.630\n",
      "16   Loss: 118.807  Accuracy: 80.781\n",
      "17   Loss: 115.486  Accuracy: 80.769\n",
      "18   Loss: 115.249  Accuracy: 81.046\n",
      "19   Loss: 114.695  Accuracy: 81.147\n",
      "20   Loss: 116.358  Accuracy: 80.504\n",
      "21   Loss: 113.981  Accuracy: 81.437\n",
      "22   Loss: 114.139  Accuracy: 81.298\n",
      "23   Loss: 114.486  Accuracy: 81.172\n",
      "24   Loss: 115.363  Accuracy: 81.122\n",
      "25   Loss: 112.503  Accuracy: 81.311\n",
      "26   Loss: 113.535  Accuracy: 81.727\n",
      "27   Loss: 110.424  Accuracy: 81.840\n",
      "28   Loss: 111.875  Accuracy: 81.853\n",
      "29   Loss: 109.639  Accuracy: 82.319\n",
      "30   Loss: 110.351  Accuracy: 82.016\n",
      "31   Loss: 108.919  Accuracy: 82.294\n",
      "32   Loss: 109.998  Accuracy: 81.966\n",
      "33   Loss: 109.503  Accuracy: 81.815\n",
      "34   Loss: 108.091  Accuracy: 82.457\n",
      "35   Loss: 109.692  Accuracy: 82.193\n",
      "36   Loss: 108.627  Accuracy: 82.218\n",
      "37   Loss: 107.200  Accuracy: 82.205\n",
      "38   Loss: 106.340  Accuracy: 82.331\n",
      "39   Loss: 105.757  Accuracy: 82.861\n",
      "40   Loss: 107.669  Accuracy: 82.647\n",
      "41   Loss: 107.064  Accuracy: 82.483\n",
      "42   Loss: 104.448  Accuracy: 82.722\n",
      "43   Loss: 105.641  Accuracy: 82.357\n",
      "44   Loss: 105.189  Accuracy: 82.773\n",
      "45   Loss: 105.456  Accuracy: 82.861\n",
      "46   Loss: 105.277  Accuracy: 82.722\n",
      "47   Loss: 103.072  Accuracy: 83.604\n",
      "48   Loss: 102.671  Accuracy: 82.987\n",
      "49   Loss: 104.840  Accuracy: 82.571\n",
      "50   Loss: 102.929  Accuracy: 83.264\n",
      "51   Loss: 103.331  Accuracy: 83.100\n",
      "52   Loss: 101.861  Accuracy: 83.403\n",
      "53   Loss: 102.736  Accuracy: 83.352\n",
      "54   Loss: 103.333  Accuracy: 83.025\n",
      "55   Loss: 103.362  Accuracy: 83.390\n",
      "56   Loss: 102.088  Accuracy: 83.340\n",
      "57   Loss: 101.216  Accuracy: 83.541\n",
      "58   Loss: 102.773  Accuracy: 83.151\n",
      "59   Loss: 100.806  Accuracy: 83.088\n",
      "60   Loss: 99.940  Accuracy: 83.680\n",
      "61   Loss: 102.393  Accuracy: 83.239\n",
      "62   Loss: 100.871  Accuracy: 84.083\n",
      "63   Loss: 100.039  Accuracy: 83.503\n",
      "64   Loss: 101.810  Accuracy: 82.810\n",
      "65   Loss: 99.152  Accuracy: 83.680\n",
      "66   Loss: 99.903  Accuracy: 83.289\n",
      "67   Loss: 99.477  Accuracy: 83.945\n",
      "68   Loss: 99.199  Accuracy: 83.680\n",
      "69   Loss: 99.086  Accuracy: 83.856\n",
      "70   Loss: 99.900  Accuracy: 84.096\n",
      "71   Loss: 100.396  Accuracy: 83.831\n",
      "72   Loss: 99.239  Accuracy: 83.856\n",
      "73   Loss: 96.731  Accuracy: 84.348\n",
      "74   Loss: 98.112  Accuracy: 84.045\n",
      "75   Loss: 98.637  Accuracy: 83.781\n",
      "76   Loss: 96.836  Accuracy: 84.297\n",
      "77   Loss: 96.263  Accuracy: 84.486\n",
      "78   Loss: 96.447  Accuracy: 84.310\n",
      "79   Loss: 98.029  Accuracy: 83.869\n",
      "80   Loss: 98.267  Accuracy: 83.957\n",
      "81   Loss: 98.349  Accuracy: 83.503\n",
      "82   Loss: 96.101  Accuracy: 83.882\n",
      "83   Loss: 95.980  Accuracy: 84.688\n",
      "84   Loss: 94.578  Accuracy: 84.650\n",
      "85   Loss: 94.792  Accuracy: 84.234\n",
      "86   Loss: 95.896  Accuracy: 84.071\n",
      "87   Loss: 95.247  Accuracy: 84.134\n",
      "88   Loss: 94.876  Accuracy: 84.260\n",
      "89   Loss: 93.706  Accuracy: 84.587\n",
      "90   Loss: 94.434  Accuracy: 84.499\n",
      "91   Loss: 93.945  Accuracy: 84.549\n",
      "92   Loss: 94.333  Accuracy: 84.600\n",
      "93   Loss: 94.513  Accuracy: 84.486\n",
      "94   Loss: 91.948  Accuracy: 84.713\n",
      "95   Loss: 93.004  Accuracy: 84.373\n",
      "96   Loss: 92.489  Accuracy: 84.991\n",
      "97   Loss: 91.786  Accuracy: 85.041\n",
      "98   Loss: 91.584  Accuracy: 85.180\n",
      "99   Loss: 92.305  Accuracy: 85.003\n",
      "100  Loss: 91.224  Accuracy: 84.461\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T15:21:24.549840Z",
     "start_time": "2024-12-02T15:21:23.448894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = []\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        y_pred.append(predicted.cpu())\n",
    "\n",
    "y_pred = torch.cat(y_pred).numpy()\n",
    "y_true = subject_label_test_tensor.to(\"cpu\").numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average=None)\n",
    "recall = recall_score(y_true, y_pred, average=None)\n",
    "f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "print(f\"Loss: {test_loss:.3f}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "for sleep_stage, precision_val, f1_val, recall_val in zip(SLEEP_STAGES, precision, recall, f1):\n",
    "    print(f\"{sleep_stage:7}precision={precision_val:.3f}  recall={recall_val:.3f}  f1={f1_val:.3f}\")"
   ],
   "id": "259b3b967d2e9748",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 30.894\n",
      "Accuracy: 0.684\n",
      "W      precision=0.874  recall=0.732  f1=0.630\n",
      "N1     precision=0.434  recall=0.496  f1=0.580\n",
      "N2     precision=0.686  recall=0.743  f1=0.810\n",
      "N3     precision=0.756  recall=0.787  f1=0.820\n",
      "REM    precision=0.744  recall=0.395  f1=0.269\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4cdda3992598712e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
