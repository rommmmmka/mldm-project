{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T19:01:03.380449Z",
     "start_time": "2024-12-01T19:01:03.364415Z"
    }
   },
   "source": [
    "import mne\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T17:19:40.635642Z",
     "start_time": "2024-12-01T17:19:40.619636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelShuffle(torch.nn.Module):\n",
    "    def __init__(self, groups):\n",
    "        super(ChannelShuffle, self).__init__()\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, length = x.size()\n",
    "        x = x.view(batch_size, self.groups, channels // self.groups, length)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, channels, length)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock1, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=8, groups=8)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle1 = ChannelShuffle(8)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=7, groups=8)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle2 = ChannelShuffle(8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock2, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 128, kernel_size=16, padding=8, stride=2, groups=16)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle1 = ChannelShuffle(16)\n",
    "        self.conv2 = torch.nn.Conv1d(128, 128, kernel_size=16, padding=7, groups=16)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle2 = ChannelShuffle(16)\n",
    "\n",
    "        self.match_dimensions = torch.nn.Conv1d(64, 128, kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        x = self.match_dimensions(x)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class LightSleepNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightSleepNet, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(1, 64, kernel_size=16, padding=7, stride=2)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(64)\n",
    "        self.residual1 = ResidualBlock1()\n",
    "        self.residual2 = ResidualBlock2()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.linear = torch.nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.residual1(x)\n",
    "        x = self.residual2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ],
   "id": "2f9ea501934a66e4",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T18:58:27.502840Z",
     "start_time": "2024-12-01T18:58:27.486778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHANNEL_NAME = \"F3\"\n",
    "ANNOTATOR = \"annotator_1\"\n",
    "SLEEP_STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]"
   ],
   "id": "9e16fe21aea1f7e7",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T17:30:52.047790Z",
     "start_time": "2024-12-01T17:30:40.777354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subjects_data = []\n",
    "subjects_labels = []\n",
    "\n",
    "for subject in range(1, 11):\n",
    "    print(f\"==={subject}===\")\n",
    "    raw = mne.io.read_raw_fif(f\"processed/{subject}/{subject}_{ANNOTATOR}_eeg.fif\")\n",
    "    raw.pick(CHANNEL_NAME)\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=30, preload=True)\n",
    "    annotations = raw.annotations\n",
    "\n",
    "    data_tensor = torch.tensor(epochs.get_data(), dtype=torch.float32).to(\"cuda\")\n",
    "\n",
    "    annotations_int = annotations.description.astype(int)\n",
    "    annotations_int[annotations_int == 5] = 4\n",
    "    labels_tensor = torch.tensor(annotations_int).to(\"cuda\")\n",
    "\n",
    "    subjects_data.append(data_tensor)\n",
    "    subjects_labels.append(labels_tensor)"
   ],
   "id": "40cf8da905c03fb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===1===\n",
      "Opening raw data file processed/1/1_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5723999 =      0.000 ... 28619.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "954 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 954 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===2===\n",
      "Opening raw data file processed/2/2_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5645999 =      0.000 ... 28229.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "941 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 941 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===3===\n",
      "Opening raw data file processed/3/3_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4943999 =      0.000 ... 24719.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "824 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 824 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===4===\n",
      "Opening raw data file processed/4/4_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4763999 =      0.000 ... 23819.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "794 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 794 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===5===\n",
      "Opening raw data file processed/5/5_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5663999 =      0.000 ... 28319.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "944 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 944 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===6===\n",
      "Opening raw data file processed/6/6_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5117999 =      0.000 ... 25589.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "853 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 853 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===7===\n",
      "Opening raw data file processed/7/7_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4883999 =      0.000 ... 24419.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "814 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 814 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===8===\n",
      "Opening raw data file processed/8/8_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5999999 =      0.000 ... 29999.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "1000 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1000 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===9===\n",
      "Opening raw data file processed/9/9_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5813999 =      0.000 ... 29069.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "969 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 969 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===10===\n",
      "Opening raw data file processed/10/10_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4775999 =      0.000 ... 23879.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "796 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 796 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T17:31:14.845715Z",
     "start_time": "2024-12-01T17:31:14.836354Z"
    }
   },
   "cell_type": "code",
   "source": "SUBJECT_TEST = 10",
   "id": "190787bae97ff60",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T18:44:34.143621Z",
     "start_time": "2024-12-01T18:03:23.197049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for subject_test in range(1, 11):\n",
    "for subject_test in [SUBJECT_TEST]:\n",
    "    print(f\"===SUBJECT TEST: {subject_test}===\")\n",
    "\n",
    "    subjects_data_train = subjects_data[:subject_test - 1] + subjects_data[subject_test:]\n",
    "    subjects_label_train = subjects_labels[:subject_test - 1] + subjects_labels[subject_test:]\n",
    "    subjects_data_train_tensor = torch.cat(subjects_data_train)\n",
    "    subjects_label_train_tensor = torch.cat(subjects_label_train)\n",
    "    train_dataset = torch.utils.data.TensorDataset(subjects_data_train_tensor, subjects_label_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    subject_data_test_tensor = subjects_data[subject_test - 1]\n",
    "    subject_label_test_tensor = subjects_labels[subject_test - 1]\n",
    "    test_dataset = torch.utils.data.TensorDataset(subject_data_test_tensor, subject_label_test_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = LightSleepNet().to(\"cuda\")\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for training_epoch in range(100):\n",
    "        print(training_epoch + 1)\n",
    "\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            outputs = model(X_batch).float()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        print(f\"train\\taccuracy: {100 * correct / total:.3f}\\tloss: {train_loss:.3f}\")\n",
    "\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "\n",
    "        print(f\"test\\taccuracy: {100 * correct / total:.3f}\\tloss: {test_loss:.3f}\")"
   ],
   "id": "86fdd41dce85cd3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===SUBJECT TEST: 10===\n",
      "1\n",
      "train   accuracy: 68.133   loss: 202.714\n",
      "test    accuracy: 30.402   loss: 41.736\n",
      "2\n",
      "train   accuracy: 75.287   loss: 156.648\n",
      "test    accuracy: 32.663   loss: 44.439\n",
      "3\n",
      "train   accuracy: 76.918   loss: 144.354\n",
      "test    accuracy: 34.171   loss: 43.188\n",
      "4\n",
      "train   accuracy: 77.511   loss: 142.161\n",
      "test    accuracy: 35.050   loss: 43.883\n",
      "5\n",
      "train   accuracy: 78.142   loss: 136.152\n",
      "test    accuracy: 34.171   loss: 50.051\n",
      "6\n",
      "train   accuracy: 78.512   loss: 136.797\n",
      "test    accuracy: 34.422   loss: 44.915\n",
      "7\n",
      "train   accuracy: 78.920   loss: 131.651\n",
      "test    accuracy: 40.955   loss: 40.709\n",
      "8\n",
      "train   accuracy: 79.538   loss: 128.536\n",
      "test    accuracy: 33.920   loss: 46.939\n",
      "9\n",
      "train   accuracy: 80.292   loss: 124.871\n",
      "test    accuracy: 37.437   loss: 44.514\n",
      "10\n",
      "train   accuracy: 80.230   loss: 124.990\n",
      "test    accuracy: 34.925   loss: 48.130\n",
      "11\n",
      "train   accuracy: 80.180   loss: 123.235\n",
      "test    accuracy: 36.055   loss: 46.055\n",
      "12\n",
      "train   accuracy: 80.279   loss: 123.655\n",
      "test    accuracy: 39.573   loss: 44.080\n",
      "13\n",
      "train   accuracy: 80.613   loss: 123.422\n",
      "test    accuracy: 38.568   loss: 44.114\n",
      "14\n",
      "train   accuracy: 80.428   loss: 121.274\n",
      "test    accuracy: 42.085   loss: 43.733\n",
      "15\n",
      "train   accuracy: 80.872   loss: 121.314\n",
      "test    accuracy: 38.442   loss: 45.809\n",
      "16\n",
      "train   accuracy: 81.119   loss: 119.564\n",
      "test    accuracy: 39.824   loss: 47.218\n",
      "17\n",
      "train   accuracy: 81.626   loss: 117.015\n",
      "test    accuracy: 40.075   loss: 45.349\n",
      "18\n",
      "train   accuracy: 81.577   loss: 118.505\n",
      "test    accuracy: 39.196   loss: 44.617\n",
      "19\n",
      "train   accuracy: 81.404   loss: 118.281\n",
      "test    accuracy: 42.839   loss: 42.637\n",
      "20\n",
      "train   accuracy: 81.181   loss: 117.566\n",
      "test    accuracy: 39.322   loss: 44.385\n",
      "21\n",
      "train   accuracy: 81.774   loss: 116.109\n",
      "test    accuracy: 40.829   loss: 46.126\n",
      "22\n",
      "train   accuracy: 81.799   loss: 114.637\n",
      "test    accuracy: 41.583   loss: 42.243\n",
      "23\n",
      "train   accuracy: 81.614   loss: 115.763\n",
      "test    accuracy: 43.216   loss: 43.035\n",
      "24\n",
      "train   accuracy: 81.688   loss: 114.615\n",
      "test    accuracy: 42.839   loss: 45.088\n",
      "25\n",
      "train   accuracy: 81.441   loss: 115.021\n",
      "test    accuracy: 41.960   loss: 45.192\n",
      "26\n",
      "train   accuracy: 82.207   loss: 112.802\n",
      "test    accuracy: 44.472   loss: 39.671\n",
      "27\n",
      "train   accuracy: 82.479   loss: 111.079\n",
      "test    accuracy: 45.352   loss: 40.410\n",
      "28\n",
      "train   accuracy: 81.972   loss: 113.273\n",
      "test    accuracy: 43.844   loss: 40.068\n",
      "29\n",
      "train   accuracy: 81.960   loss: 111.309\n",
      "test    accuracy: 43.970   loss: 40.973\n",
      "30\n",
      "train   accuracy: 82.170   loss: 112.256\n",
      "test    accuracy: 44.975   loss: 41.735\n",
      "31\n",
      "train   accuracy: 82.812   loss: 108.497\n",
      "test    accuracy: 44.598   loss: 42.191\n",
      "32\n",
      "train   accuracy: 82.924   loss: 108.020\n",
      "test    accuracy: 46.734   loss: 39.077\n",
      "33\n",
      "train   accuracy: 82.244   loss: 109.134\n",
      "test    accuracy: 48.995   loss: 38.860\n",
      "34\n",
      "train   accuracy: 82.318   loss: 108.601\n",
      "test    accuracy: 45.980   loss: 44.135\n",
      "35\n",
      "train   accuracy: 82.973   loss: 109.956\n",
      "test    accuracy: 44.095   loss: 43.840\n",
      "36\n",
      "train   accuracy: 82.738   loss: 107.446\n",
      "test    accuracy: 46.106   loss: 38.305\n",
      "37\n",
      "train   accuracy: 83.245   loss: 106.303\n",
      "test    accuracy: 45.854   loss: 41.540\n",
      "38\n",
      "train   accuracy: 82.812   loss: 108.504\n",
      "test    accuracy: 48.869   loss: 37.167\n",
      "39\n",
      "train   accuracy: 83.121   loss: 105.943\n",
      "test    accuracy: 47.990   loss: 38.959\n",
      "40\n",
      "train   accuracy: 83.208   loss: 106.550\n",
      "test    accuracy: 43.090   loss: 44.215\n",
      "41\n",
      "train   accuracy: 83.245   loss: 105.508\n",
      "test    accuracy: 47.111   loss: 38.022\n",
      "42\n",
      "train   accuracy: 83.307   loss: 105.141\n",
      "test    accuracy: 49.874   loss: 38.839\n",
      "43\n",
      "train   accuracy: 83.059   loss: 106.589\n",
      "test    accuracy: 47.864   loss: 38.625\n",
      "44\n",
      "train   accuracy: 83.405   loss: 105.417\n",
      "test    accuracy: 46.231   loss: 42.177\n",
      "45\n",
      "train   accuracy: 82.998   loss: 105.281\n",
      "test    accuracy: 47.111   loss: 42.113\n",
      "46\n",
      "train   accuracy: 83.418   loss: 105.645\n",
      "test    accuracy: 50.126   loss: 37.104\n",
      "47\n",
      "train   accuracy: 83.319   loss: 103.673\n",
      "test    accuracy: 50.754   loss: 36.128\n",
      "48\n",
      "train   accuracy: 83.319   loss: 104.047\n",
      "test    accuracy: 49.246   loss: 40.304\n",
      "49\n",
      "train   accuracy: 83.591   loss: 102.888\n",
      "test    accuracy: 51.005   loss: 37.950\n",
      "50\n",
      "train   accuracy: 83.690   loss: 102.146\n",
      "test    accuracy: 49.749   loss: 38.039\n",
      "51\n",
      "train   accuracy: 83.344   loss: 103.636\n",
      "test    accuracy: 50.754   loss: 39.090\n",
      "52\n",
      "train   accuracy: 83.714   loss: 100.427\n",
      "test    accuracy: 52.764   loss: 37.926\n",
      "53\n",
      "train   accuracy: 83.554   loss: 103.208\n",
      "test    accuracy: 53.643   loss: 36.778\n",
      "54\n",
      "train   accuracy: 83.245   loss: 103.253\n",
      "test    accuracy: 53.518   loss: 37.162\n",
      "55\n",
      "train   accuracy: 83.887   loss: 101.322\n",
      "test    accuracy: 51.759   loss: 38.207\n",
      "56\n",
      "train   accuracy: 83.615   loss: 102.573\n",
      "test    accuracy: 53.392   loss: 37.918\n",
      "57\n",
      "train   accuracy: 83.393   loss: 101.598\n",
      "test    accuracy: 52.513   loss: 39.039\n",
      "58\n",
      "train   accuracy: 83.924   loss: 99.728\n",
      "test    accuracy: 50.503   loss: 37.866\n",
      "59\n",
      "train   accuracy: 83.739   loss: 99.434\n",
      "test    accuracy: 51.884   loss: 38.956\n",
      "60\n",
      "train   accuracy: 83.924   loss: 99.443\n",
      "test    accuracy: 53.643   loss: 36.382\n",
      "61\n",
      "train   accuracy: 84.172   loss: 99.220\n",
      "test    accuracy: 53.266   loss: 37.000\n",
      "62\n",
      "train   accuracy: 83.850   loss: 98.342\n",
      "test    accuracy: 50.628   loss: 41.991\n",
      "63\n",
      "train   accuracy: 84.196   loss: 99.747\n",
      "test    accuracy: 52.638   loss: 38.020\n",
      "64\n",
      "train   accuracy: 84.332   loss: 98.779\n",
      "test    accuracy: 54.523   loss: 36.961\n",
      "65\n",
      "train   accuracy: 83.813   loss: 100.406\n",
      "test    accuracy: 51.633   loss: 37.941\n",
      "66\n",
      "train   accuracy: 83.961   loss: 98.902\n",
      "test    accuracy: 53.769   loss: 38.773\n",
      "67\n",
      "train   accuracy: 84.616   loss: 95.851\n",
      "test    accuracy: 54.020   loss: 35.770\n",
      "68\n",
      "train   accuracy: 83.912   loss: 98.172\n",
      "test    accuracy: 53.894   loss: 37.725\n",
      "69\n",
      "train   accuracy: 84.616   loss: 96.951\n",
      "test    accuracy: 54.020   loss: 36.645\n",
      "70\n",
      "train   accuracy: 84.196   loss: 97.165\n",
      "test    accuracy: 53.141   loss: 36.880\n",
      "71\n",
      "train   accuracy: 84.616   loss: 96.479\n",
      "test    accuracy: 55.402   loss: 37.814\n",
      "72\n",
      "train   accuracy: 84.826   loss: 95.139\n",
      "test    accuracy: 55.025   loss: 38.128\n",
      "73\n",
      "train   accuracy: 84.592   loss: 96.025\n",
      "test    accuracy: 54.523   loss: 36.384\n",
      "74\n",
      "train   accuracy: 84.715   loss: 95.795\n",
      "test    accuracy: 56.658   loss: 34.613\n",
      "75\n",
      "train   accuracy: 84.777   loss: 94.932\n",
      "test    accuracy: 55.653   loss: 36.640\n",
      "76\n",
      "train   accuracy: 85.111   loss: 93.319\n",
      "test    accuracy: 55.276   loss: 35.180\n",
      "77\n",
      "train   accuracy: 84.863   loss: 94.713\n",
      "test    accuracy: 56.156   loss: 36.139\n",
      "78\n",
      "train   accuracy: 84.814   loss: 94.277\n",
      "test    accuracy: 56.281   loss: 37.136\n",
      "79\n",
      "train   accuracy: 85.370   loss: 92.175\n",
      "test    accuracy: 54.020   loss: 38.669\n",
      "80\n",
      "train   accuracy: 84.542   loss: 94.249\n",
      "test    accuracy: 57.412   loss: 35.736\n",
      "81\n",
      "train   accuracy: 85.197   loss: 92.983\n",
      "test    accuracy: 55.905   loss: 35.910\n",
      "82\n",
      "train   accuracy: 85.358   loss: 92.300\n",
      "test    accuracy: 54.020   loss: 38.495\n",
      "83\n",
      "train   accuracy: 85.605   loss: 90.540\n",
      "test    accuracy: 53.392   loss: 40.691\n",
      "84\n",
      "train   accuracy: 85.209   loss: 93.384\n",
      "test    accuracy: 55.025   loss: 37.970\n",
      "85\n",
      "train   accuracy: 85.172   loss: 91.809\n",
      "test    accuracy: 57.412   loss: 36.737\n",
      "86\n",
      "train   accuracy: 85.741   loss: 90.294\n",
      "test    accuracy: 55.025   loss: 38.066\n",
      "87\n",
      "train   accuracy: 85.148   loss: 91.987\n",
      "test    accuracy: 56.533   loss: 37.523\n",
      "88\n",
      "train   accuracy: 85.691   loss: 88.920\n",
      "test    accuracy: 56.533   loss: 36.858\n",
      "89\n",
      "train   accuracy: 85.333   loss: 90.274\n",
      "test    accuracy: 55.276   loss: 38.791\n",
      "90\n",
      "train   accuracy: 85.555   loss: 89.505\n",
      "test    accuracy: 56.156   loss: 39.349\n",
      "91\n",
      "train   accuracy: 85.481   loss: 90.143\n",
      "test    accuracy: 54.899   loss: 38.708\n",
      "92\n",
      "train   accuracy: 85.555   loss: 90.428\n",
      "test    accuracy: 57.412   loss: 35.779\n",
      "93\n",
      "train   accuracy: 85.852   loss: 87.256\n",
      "test    accuracy: 53.141   loss: 39.392\n",
      "94\n",
      "train   accuracy: 85.580   loss: 89.589\n",
      "test    accuracy: 56.784   loss: 38.066\n",
      "95\n",
      "train   accuracy: 85.741   loss: 88.003\n",
      "test    accuracy: 51.884   loss: 42.363\n",
      "96\n",
      "train   accuracy: 85.568   loss: 89.136\n",
      "test    accuracy: 55.151   loss: 39.380\n",
      "97\n",
      "train   accuracy: 85.765   loss: 88.145\n",
      "test    accuracy: 55.779   loss: 37.562\n",
      "98\n",
      "train   accuracy: 85.889   loss: 86.983\n",
      "test    accuracy: 53.643   loss: 39.459\n",
      "99\n",
      "train   accuracy: 85.370   loss: 87.436\n",
      "test    accuracy: 55.528   loss: 40.128\n",
      "100\n",
      "train   accuracy: 86.050   loss: 86.404\n",
      "test    accuracy: 55.025   loss: 37.893\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:04:43.657420Z",
     "start_time": "2024-12-01T19:04:42.842140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = outputs.max(1)\n",
    "        y_pred.append(predicted.cpu())\n",
    "\n",
    "y_pred = torch.cat(y_pred).numpy()\n",
    "y_true = subject_label_test_tensor.to(\"cpu\").numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average=None)\n",
    "recall = recall_score(y_true, y_pred, average=None)\n",
    "f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "for sleep_stage, precision_val, f1_val, recall_val in zip(SLEEP_STAGES, precision, recall, f1):\n",
    "    print(f\"{sleep_stage:7}precision={precision_val:.3f}  recall={recall_val:.3f}  f1={f1_val:.3f}\")"
   ],
   "id": "259b3b967d2e9748",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.553\n",
      "W      precision=0.669  recall=0.620  f1=0.578\n",
      "N1     precision=0.584  recall=0.492  f1=0.425\n",
      "N2     precision=0.396  recall=0.523  f1=0.768\n",
      "N3     precision=0.776  recall=0.789  f1=0.804\n",
      "REM    precision=0.780  recall=0.364  f1=0.237\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78da43f011334995"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
