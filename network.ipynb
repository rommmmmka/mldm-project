{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T23:34:08.140261Z",
     "start_time": "2024-12-18T23:34:01.367273Z"
    }
   },
   "source": [
    "import mne\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from lightsleepnet import LightSleepNet"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T23:34:08.958951Z",
     "start_time": "2024-12-18T23:34:08.943545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHANNEL_NAME = \"F3\"\n",
    "ANNOTATOR = \"annotator_1\"\n",
    "SLEEP_STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]"
   ],
   "id": "9e16fe21aea1f7e7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T23:34:28.831975Z",
     "start_time": "2024-12-18T23:34:09.529113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subjects_data = []\n",
    "subjects_labels = []\n",
    "\n",
    "for subject in range(1, 11):\n",
    "    print(f\"==={subject}===\")\n",
    "    raw = mne.io.read_raw_fif(f\"processed/{subject}/{subject}_{ANNOTATOR}_eeg.fif\")\n",
    "    raw.pick(CHANNEL_NAME)\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=30, preload=True)\n",
    "    annotations = raw.annotations\n",
    "\n",
    "    data_tensor = torch.tensor(epochs.get_data(), dtype=torch.float32).to(\"cuda\")\n",
    "\n",
    "    annotations_int = annotations.description.astype(int)\n",
    "    annotations_int[annotations_int == 5] = 4\n",
    "    labels_tensor = torch.tensor(annotations_int).to(\"cuda\")\n",
    "\n",
    "    subjects_data.append(data_tensor)\n",
    "    subjects_labels.append(labels_tensor)"
   ],
   "id": "40cf8da905c03fb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===1===\n",
      "Opening raw data file processed/1/1_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5723999 =      0.000 ... 28619.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "954 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 954 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===2===\n",
      "Opening raw data file processed/2/2_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5645999 =      0.000 ... 28229.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "941 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 941 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===3===\n",
      "Opening raw data file processed/3/3_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4943999 =      0.000 ... 24719.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "824 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 824 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===4===\n",
      "Opening raw data file processed/4/4_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4763999 =      0.000 ... 23819.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "794 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 794 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===5===\n",
      "Opening raw data file processed/5/5_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5663999 =      0.000 ... 28319.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "944 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 944 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===6===\n",
      "Opening raw data file processed/6/6_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5117999 =      0.000 ... 25589.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "853 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 853 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===7===\n",
      "Opening raw data file processed/7/7_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4883999 =      0.000 ... 24419.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "814 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 814 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===8===\n",
      "Opening raw data file processed/8/8_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5999999 =      0.000 ... 29999.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "1000 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1000 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===9===\n",
      "Opening raw data file processed/9/9_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5813999 =      0.000 ... 29069.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "969 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 969 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n",
      "===10===\n",
      "Opening raw data file processed/10/10_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 4775999 =      0.000 ... 23879.995 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "796 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 796 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T23:34:31.420039Z",
     "start_time": "2024-12-18T23:34:31.404113Z"
    }
   },
   "cell_type": "code",
   "source": "SUBJECT_TEST = 1",
   "id": "190787bae97ff60",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T23:46:52.983195Z",
     "start_time": "2024-12-18T23:43:24.275814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for subject_test in range(1, 11):\n",
    "for subject_test in [SUBJECT_TEST]:\n",
    "    print(f\"===TEST SUBJECT: {subject_test}===\")\n",
    "\n",
    "    subjects_data_train = subjects_data[:subject_test - 1] + subjects_data[subject_test:]\n",
    "    subjects_label_train = subjects_labels[:subject_test - 1] + subjects_labels[subject_test:]\n",
    "    subjects_data_train_tensor = torch.cat(subjects_data_train)\n",
    "    subjects_label_train_tensor = torch.cat(subjects_label_train)\n",
    "    train_dataset = torch.utils.data.TensorDataset(subjects_data_train_tensor, subjects_label_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    subject_data_test_tensor = subjects_data[subject_test - 1]\n",
    "    subject_label_test_tensor = subjects_labels[subject_test - 1]\n",
    "    test_dataset = torch.utils.data.TensorDataset(subject_data_test_tensor, subject_label_test_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = LightSleepNet().to(\"cuda\")\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for training_epoch in range(100):\n",
    "        print(f\"{training_epoch + 1:<5}\", end=\"\")\n",
    "\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch.requires_grad = True\n",
    "\n",
    "            outputs = model(X_batch).float()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            weights = []\n",
    "\n",
    "            for epoch_idx in range(X_batch.size(0)):\n",
    "                epoch_data = X_batch[epoch_idx].unsqueeze(0)\n",
    "                epoch_loss = criterion(model(epoch_data), y_batch[epoch_idx].unsqueeze(0))\n",
    "\n",
    "                epoch_grads = torch.autograd.grad(epoch_loss, epoch_data, retain_graph=True)[0]\n",
    "                grad_norms = epoch_grads.norm(p=2, dim=1).squeeze(0)\n",
    "\n",
    "                delta = 0.1 * grad_norms.std().item()\n",
    "                density = ((grad_norms.unsqueeze(1) - grad_norms.unsqueeze(0)).abs() < delta).sum(dim=1).float()\n",
    "\n",
    "                epoch_weight = density.mean()\n",
    "                weights.append(epoch_weight.detach())\n",
    "\n",
    "            weights = torch.tensor(weights, device=\"cuda\")\n",
    "            weights /= weights.sum()\n",
    "            # print(weights)\n",
    "            weighted_loss = (weights * loss).sum()\n",
    "            train_loss += weighted_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            weighted_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        print(f\"Loss: {train_loss / len(train_loader):.3f}  Accuracy: {100 * correct / total:.3f}\")"
   ],
   "id": "86fdd41dce85cd3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===TEST SUBJECT: 1===\n",
      "1    Loss: 0.789  Accuracy: 68.116\n",
      "2    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T23:46:58.872472Z",
     "start_time": "2024-12-18T23:46:58.218504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = []\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(\n",
    "            X_batch,\n",
    "            (\n",
    "                subject_data_test_tensor.mean(dim=(0, 2)),\n",
    "                subject_data_test_tensor.var(dim=(0, 2), unbiased=False)\n",
    "            )\n",
    "        )\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        y_pred.append(predicted.cpu())\n",
    "\n",
    "y_pred = torch.cat(y_pred).numpy()\n",
    "y_true = subject_label_test_tensor.to(\"cpu\").numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average=None)\n",
    "recall = recall_score(y_true, y_pred, average=None)\n",
    "f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "print(f\"Loss: {test_loss / len(test_loader):.3f}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "for sleep_stage, precision_val, f1_val, recall_val in zip(SLEEP_STAGES, precision, recall, f1):\n",
    "    print(f\"{sleep_stage:7}precision={precision_val:.3f}  recall={recall_val:.3f}  f1={f1_val:.3f}\")"
   ],
   "id": "259b3b967d2e9748",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 14\u001B[0m\n\u001B[0;32m      6\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\n\u001B[0;32m      7\u001B[0m     X_batch,\n\u001B[0;32m      8\u001B[0m     (\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m     )\n\u001B[0;32m     12\u001B[0m )\n\u001B[0;32m     13\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_batch)\n\u001B[1;32m---> 14\u001B[0m test_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     16\u001B[0m y_pred\u001B[38;5;241m.\u001B[39mappend(predicted\u001B[38;5;241m.\u001B[39mcpu())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "181155bd6fef87c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
