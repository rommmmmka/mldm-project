{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:52.662761Z",
     "start_time": "2024-12-01T12:43:50.757358Z"
    }
   },
   "source": [
    "import mne\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:53.078482Z",
     "start_time": "2024-12-01T12:43:53.046439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelShuffle(torch.nn.Module):\n",
    "    def __init__(self, groups):\n",
    "        super(ChannelShuffle, self).__init__()\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, length = x.size()\n",
    "        x = x.view(batch_size, self.groups, channels // self.groups, length)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, channels, length)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock1, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=8, groups=8)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle1 = ChannelShuffle(8)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 64, kernel_size=16, padding=7, groups=8)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(64)\n",
    "        self.shuffle2 = ChannelShuffle(8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock2, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(64, 128, kernel_size=16, padding=8, stride=2, groups=16)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle1 = ChannelShuffle(16)\n",
    "        self.conv2 = torch.nn.Conv1d(128, 128, kernel_size=16, padding=7, groups=16)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(128)\n",
    "        self.shuffle2 = ChannelShuffle(16)\n",
    "\n",
    "        self.match_dimensions = torch.nn.Conv1d(64, 128, kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.shuffle2(out)\n",
    "\n",
    "        x = self.match_dimensions(x)\n",
    "\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class LightSleepNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightSleepNet, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(1, 64, kernel_size=16, padding=7, stride=2)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(64)\n",
    "        self.residual1 = ResidualBlock1()\n",
    "        self.residual2 = ResidualBlock2()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.linear = torch.nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.residual1(x)\n",
    "        x = self.residual2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ],
   "id": "2f9ea501934a66e4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:53.886397Z",
     "start_time": "2024-12-01T12:43:53.870553Z"
    }
   },
   "cell_type": "code",
   "source": "SUBJECT = 1",
   "id": "9e16fe21aea1f7e7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:55.537412Z",
     "start_time": "2024-12-01T12:43:54.282670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw = mne.io.read_raw_fif(f\"processed/{SUBJECT}/{SUBJECT}_annotator_1_eeg.fif\")\n",
    "channel_names = raw.ch_names\n",
    "channel_names"
   ],
   "id": "77c70f7f66b61910",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file processed/1/1_annotator_1_eeg.fif...\n",
      "    Range : 0 ... 5723999 =      0.000 ... 28619.995 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['F3', 'C3', 'O1', 'F4', 'C4', 'O2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:56.503894Z",
     "start_time": "2024-12-01T12:43:55.537412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw.pick(channel_names[0])\n",
    "epochs = mne.make_fixed_length_epochs(raw, duration=30, preload=True)\n",
    "annotations = raw.annotations"
   ],
   "id": "5250594f0aeace54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "954 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 954 events and 6000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:56.822045Z",
     "start_time": "2024-12-01T12:43:56.535412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_tensor = torch.tensor(epochs.get_data(), dtype=torch.float32).to(\"cuda\")\n",
    "data_tensor"
   ],
   "id": "dfdc9ea9264e3882",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.7221e-09, -1.2322e-07, -9.0448e-07,  ...,  1.1952e-06,\n",
       "           8.0148e-07,  2.9259e-07]],\n",
       "\n",
       "        [[ 1.4076e-07,  5.7259e-07,  1.2287e-06,  ..., -4.3679e-07,\n",
       "          -1.5679e-07, -4.7951e-07]],\n",
       "\n",
       "        [[-8.5183e-07, -7.4884e-07, -2.8801e-07,  ...,  5.5505e-07,\n",
       "           4.8791e-07,  1.1929e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4363e-06,  1.9024e-06,  2.1679e-06,  ...,  3.6915e-06,\n",
       "           2.6608e-06,  6.2829e-07]],\n",
       "\n",
       "        [[-2.1630e-07,  1.6255e-06,  4.6689e-06,  ...,  9.3061e-06,\n",
       "           9.2466e-06,  9.2840e-06]],\n",
       "\n",
       "        [[ 9.4373e-06,  9.4930e-06,  9.2550e-06,  ..., -9.7391e-07,\n",
       "          -1.1395e-06, -1.1578e-06]]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:57.502735Z",
     "start_time": "2024-12-01T12:43:57.455021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels_tensor = torch.tensor(list(map(int, annotations.description))).to(\"cuda\")\n",
    "labels_tensor"
   ],
   "id": "4918d99b77fffed4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 0,\n",
       "        1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 0, 1, 2, 2,\n",
       "        2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 1, 1, 1,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1,\n",
       "        1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 2, 2, 1, 1, 5, 5, 5, 1,\n",
       "        1, 0, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 0, 1, 0, 0, 1, 0, 0, 1, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 5, 5, 5, 5, 1, 1, 1, 1, 1, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        1, 1, 5, 5, 5, 5, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 5, 1, 5, 5, 1, 5, 5, 5, 5, 5, 0, 1,\n",
       "        1, 1, 1, 2, 2, 2, 5, 5, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 5, 5, 5, 5, 5, 1, 1,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:43:58.227290Z",
     "start_time": "2024-12-01T12:43:58.212625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(data_tensor, labels_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "583a5139a302a49f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:44:00.370941Z",
     "start_time": "2024-12-01T12:43:59.296512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = LightSleepNet().to(\"cuda\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "id": "6896f24437164264",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:44:23.622328Z",
     "start_time": "2024-12-01T12:44:22.889302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "for training_epoch in range(10):\n",
    "    print(training_epoch + 1)\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        outputs = model(X_batch).float()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "84e73380be152064",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_batch)\n\u001B[0;32m      8\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 9\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\PycharmProjects\\mldm-project\\.venv\\lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mldm-project\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:340\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    331\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    332\u001B[0m     (inputs,)\n\u001B[0;32m    333\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, (torch\u001B[38;5;241m.\u001B[39mTensor, graph\u001B[38;5;241m.\u001B[39mGradientEdge))\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    336\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m ()\n\u001B[0;32m    337\u001B[0m )\n\u001B[0;32m    339\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001B[38;5;28mlen\u001B[39m(tensors))\n\u001B[1;32m--> 340\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m \u001B[43m_make_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_grads_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n",
      "File \u001B[1;32m~\\PycharmProjects\\mldm-project\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:220\u001B[0m, in \u001B[0;36m_make_grads\u001B[1;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, torch\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[0;32m    219\u001B[0m         new_grads\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 220\u001B[0m             \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m         )\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    223\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:44:05.990377Z",
     "start_time": "2024-12-01T12:44:05.974724Z"
    }
   },
   "cell_type": "code",
   "source": "outputs.shape",
   "id": "f5c05bc318a28d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:44:07.023146Z",
     "start_time": "2024-12-01T12:44:07.007367Z"
    }
   },
   "cell_type": "code",
   "source": "y_batch",
   "id": "4f175516b6507918",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 2, 5, 2, 2, 0, 5, 3, 1, 3, 0, 2, 3, 2, 2, 3, 1, 2, 5, 2, 0, 5, 0, 5,\n",
       "        2, 2, 0, 5, 1, 3, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:44:08.848243Z",
     "start_time": "2024-12-01T12:44:08.816255Z"
    }
   },
   "cell_type": "code",
   "source": "torch.softmax(outputs, dim=1)",
   "id": "7dd0d6409dfb999b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2433, 0.2324, 0.1811, 0.1750, 0.1682],\n",
       "        [0.2735, 0.2521, 0.2123, 0.1659, 0.0963],\n",
       "        [0.2515, 0.2349, 0.1855, 0.1729, 0.1551],\n",
       "        [0.2714, 0.2436, 0.2120, 0.1664, 0.1066],\n",
       "        [0.2654, 0.2431, 0.2113, 0.1668, 0.1135],\n",
       "        [0.2454, 0.2327, 0.1839, 0.1754, 0.1627],\n",
       "        [0.2460, 0.2311, 0.1839, 0.1773, 0.1617],\n",
       "        [0.2709, 0.2559, 0.2200, 0.1692, 0.0841],\n",
       "        [0.2507, 0.2331, 0.1841, 0.1752, 0.1568],\n",
       "        [0.2588, 0.2389, 0.2030, 0.1744, 0.1249],\n",
       "        [0.2679, 0.2570, 0.2009, 0.1724, 0.1019],\n",
       "        [0.2704, 0.2423, 0.2064, 0.1706, 0.1104],\n",
       "        [0.2778, 0.2468, 0.2229, 0.1668, 0.0857],\n",
       "        [0.2653, 0.2427, 0.2051, 0.1697, 0.1172],\n",
       "        [0.2558, 0.2372, 0.1947, 0.1773, 0.1351],\n",
       "        [0.2752, 0.2469, 0.2284, 0.1621, 0.0875],\n",
       "        [0.2482, 0.2310, 0.1789, 0.1736, 0.1683],\n",
       "        [0.2676, 0.2466, 0.2081, 0.1748, 0.1028],\n",
       "        [0.2407, 0.2355, 0.1766, 0.1754, 0.1718],\n",
       "        [0.2494, 0.2376, 0.1844, 0.1731, 0.1555],\n",
       "        [0.2879, 0.2575, 0.2331, 0.1589, 0.0626],\n",
       "        [0.2462, 0.2330, 0.1769, 0.1736, 0.1702],\n",
       "        [0.2704, 0.2616, 0.2063, 0.1688, 0.0929],\n",
       "        [0.2441, 0.2344, 0.1777, 0.1746, 0.1692],\n",
       "        [0.2633, 0.2477, 0.1924, 0.1670, 0.1297],\n",
       "        [0.2737, 0.2410, 0.2103, 0.1680, 0.1069],\n",
       "        [0.2436, 0.2264, 0.1787, 0.1775, 0.1738],\n",
       "        [0.2433, 0.2318, 0.1810, 0.1739, 0.1699],\n",
       "        [0.2530, 0.2395, 0.1877, 0.1750, 0.1447],\n",
       "        [0.2634, 0.2409, 0.2043, 0.1736, 0.1179],\n",
       "        [0.2540, 0.2470, 0.2002, 0.1696, 0.1291],\n",
       "        [0.2423, 0.2345, 0.1759, 0.1760, 0.1714]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:20:55.146609Z",
     "start_time": "2024-12-01T12:20:55.099622Z"
    }
   },
   "cell_type": "code",
   "source": "torch.argmax(outputs, dim=1)",
   "id": "751adbc8de460ae2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "83c23547f75848c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
